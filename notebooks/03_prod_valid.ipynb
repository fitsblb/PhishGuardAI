{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5dc52e5",
   "metadata": {},
   "source": [
    "## **Verify Model Artifacts**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8289c920",
   "metadata": {},
   "source": [
    "### **Section 0: Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6727ac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d02036",
   "metadata": {},
   "source": [
    "- **Set working directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51094118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: d:\\MLops\\NetworkSecurity\n",
      "[feature_extraction] Loaded 1401 TLD probabilities\n"
     ]
    }
   ],
   "source": [
    "# Set working directory to project root\n",
    "if Path.cwd().name == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "print(f\"Working directory: {Path.cwd()}\")\n",
    "\n",
    "# Add src to path so we can import common modules\n",
    "sys.path.insert(0, str(Path.cwd() / \"src\"))\n",
    "from common.feature_extraction import extract_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb5850",
   "metadata": {},
   "source": [
    "### **Section 1: Check 8-Feature Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "831fa2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFYING 8-FEATURE MODEL (PRODUCTION)\n",
      "============================================================\n",
      "\n",
      "1. Model Type: <class 'sklearn.calibration.CalibratedClassifierCV'>\n",
      "   Classes: [0 1]\n",
      "   Calibration: ✅ CalibratedClassifierCV detected\n",
      "   Base estimator: XGBClassifier\n",
      "\n",
      "2. Metadata:\n",
      "   Features (8):\n",
      "      1. IsHTTPS\n",
      "      2. TLDLegitimateProb\n",
      "      3. CharContinuationRate\n",
      "      4. SpacialCharRatioInURL\n",
      "      5. URLCharProb\n",
      "      6. LetterRatioInURL\n",
      "      7. NoOfOtherSpecialCharsInURL\n",
      "      8. DomainLength\n",
      "\n",
      "3. Class Mapping:\n",
      "   Phish (0) at column index: 0\n",
      "   Class mapping: {'phish': 0, 'legit': 1}\n",
      "\n",
      "4. Performance Metrics:\n",
      "   pr_auc: 0.9991584033257773\n",
      "   f1_macro: 0.9969925280550227\n",
      "   brier: 0.0026371303574400343\n",
      "\n",
      "============================================================\n",
      "EXPECTED VALUES:\n",
      "============================================================\n",
      "✅ Classes: [0 1]\n",
      "✅ Features: 8 (IsHTTPS + 7 URL features)\n",
      "✅ Phish column index: 0\n",
      "✅ PR-AUC: ~0.999\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"VERIFYING 8-FEATURE MODEL (PRODUCTION)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load model\n",
    "model_path = Path(\"models/dev/model_8feat.pkl\")\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "print(f\"\\n1. Model Type: {type(model)}\")\n",
    "print(f\"   Classes: {model.classes_}\")\n",
    "\n",
    "# Check if it's calibrated\n",
    "if hasattr(model, \"calibrated_classifiers_\"):\n",
    "    print(f\"   Calibration: ✅ CalibratedClassifierCV detected\")\n",
    "    base = model.calibrated_classifiers_[0].estimator\n",
    "    print(f\"   Base estimator: {type(base).__name__}\")\n",
    "else:\n",
    "    print(f\"   Calibration: ❌ No calibration wrapper found\")\n",
    "\n",
    "# Load metadata\n",
    "meta_path = Path(\"models/dev/model_8feat_meta.json\")\n",
    "meta = json.load(open(meta_path))\n",
    "\n",
    "print(f\"\\n2. Metadata:\")\n",
    "print(f\"   Features ({len(meta['feature_order'])}):\")\n",
    "for i, feat in enumerate(meta[\"feature_order\"], 1):\n",
    "    print(f\"      {i}. {feat}\")\n",
    "\n",
    "print(f\"\\n3. Class Mapping:\")\n",
    "print(f\"   Phish (0) at column index: {meta['phish_proba_col_index']}\")\n",
    "print(f\"   Class mapping: {meta.get('class_mapping', 'NOT FOUND')}\")\n",
    "\n",
    "print(f\"\\n4. Performance Metrics:\")\n",
    "if \"metrics\" in meta:\n",
    "    for key, val in meta[\"metrics\"].items():\n",
    "        print(f\"   {key}: {val}\")\n",
    "else:\n",
    "    print(\"   ⚠️ No metrics found in metadata\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPECTED VALUES:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"✅ Classes: [0 1]\")\n",
    "print(\"✅ Features: 8 (IsHTTPS + 7 URL features)\")\n",
    "print(\"✅ Phish column index: 0\")\n",
    "print(\"✅ PR-AUC: ~0.999\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d10f6c8",
   "metadata": {},
   "source": [
    "### **Section 2: Quick Prediction Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa664259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PREDICTION TEST WITH WHITELIST INTEGRATION\n",
      "============================================================\n",
      "✓ Imported whitelist function\n",
      "✓ Known legitimate domains: 26 entries\n",
      "  Sample domains: ['microsoft.com', 'www.apple.com', 'www.youtube.com', 'facebook.com', 'www.wikipedia.org']\n",
      "\n",
      "------------------------------------------------------------\n",
      "WHITELIST TESTS\n",
      "------------------------------------------------------------\n",
      "✅ WHITELISTED        https://google.com\n",
      "✅ WHITELISTED        https://www.github.com\n",
      "✅ WHITELISTED        https://microsoft.com/login\n",
      "❌ NOT WHITELISTED    https://example.com/login?id=123\n",
      "❌ NOT WHITELISTED    http://suspicious-phishing-site.top/verify-account\n",
      "\n",
      "------------------------------------------------------------\n",
      "MODEL PREDICTION WITH WHITELIST INTEGRATION\n",
      "------------------------------------------------------------\n",
      "\n",
      "Testing URL: https://google.com\n",
      "✅ WHITELIST HIT: https://google.com\n",
      "   → Bypassing model prediction\n",
      "   → p_malicious = 0.01 (whitelist override)\n",
      "   → source = 'whitelist'\n",
      "\n",
      "============================================================\n",
      "CONCLUSION:\n",
      "============================================================\n",
      "✅ Whitelist function imported successfully\n",
      "✅ Major tech domains bypass model prediction\n",
      "✅ Fast-path optimization working as designed\n",
      "✅ Production model service logic validated\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREDICTION TEST WITH WHITELIST INTEGRATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Import whitelist function from model service\n",
    "from model_svc.main import _check_whitelist, KNOWN_LEGITIMATE_DOMAINS\n",
    "\n",
    "print(f\"✓ Imported whitelist function\")\n",
    "print(f\"✓ Known legitimate domains: {len(KNOWN_LEGITIMATE_DOMAINS)} entries\")\n",
    "print(f\"  Sample domains: {list(KNOWN_LEGITIMATE_DOMAINS)[:5]}\")\n",
    "\n",
    "# Test URLs including whitelisted ones\n",
    "test_urls_with_whitelist = [\n",
    "    \"https://google.com\",\n",
    "    \"https://www.github.com\",\n",
    "    \"https://microsoft.com/login\",\n",
    "    \"https://example.com/login?id=123\",  # Not whitelisted\n",
    "    \"http://suspicious-phishing-site.top/verify-account\",  # Not whitelisted\n",
    "]\n",
    "\n",
    "print(f\"\\n\" + \"-\" * 60)\n",
    "print(\"WHITELIST TESTS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for test_url in test_urls_with_whitelist:\n",
    "    is_whitelisted = _check_whitelist(test_url)\n",
    "    status = \"✅ WHITELISTED\" if is_whitelisted else \"❌ NOT WHITELISTED\"\n",
    "    print(f\"{status:20s} {test_url}\")\n",
    "\n",
    "print(f\"\\n\" + \"-\" * 60)\n",
    "print(\"MODEL PREDICTION WITH WHITELIST INTEGRATION\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Test feature array (simulating google.com features)\n",
    "test_features = {\n",
    "    \"IsHTTPS\": 1.0,\n",
    "    \"TLDLegitimateProb\": 0.6111,\n",
    "    \"CharContinuationRate\": 0.1765,\n",
    "    \"SpacialCharRatioInURL\": 0.2222,\n",
    "    \"URLCharProb\": 0.06,\n",
    "    \"LetterRatioInURL\": 0.7778,\n",
    "    \"NoOfOtherSpecialCharsInURL\": 4.0,\n",
    "    \"DomainLength\": 10.0,\n",
    "}\n",
    "\n",
    "# Simulate full prediction pipeline (like model service does)\n",
    "google_url = \"https://google.com\"\n",
    "\n",
    "print(f\"\\nTesting URL: {google_url}\")\n",
    "\n",
    "# Step 1: Check whitelist first (fast path)\n",
    "if _check_whitelist(google_url):\n",
    "    print(f\"✅ WHITELIST HIT: {google_url}\")\n",
    "    print(f\"   → Bypassing model prediction\")\n",
    "    print(f\"   → p_malicious = 0.01 (whitelist override)\")\n",
    "    print(f\"   → source = 'whitelist'\")\n",
    "else:\n",
    "    print(f\"❌ NOT WHITELISTED: Proceeding with model prediction...\")\n",
    "\n",
    "    # Step 2: Model prediction (only if not whitelisted)\n",
    "    feature_array = np.array([[test_features[f] for f in meta[\"feature_order\"]]])\n",
    "\n",
    "    print(f\"\\nTest input (google.com-like features):\")\n",
    "    print(f\"  Shape: {feature_array.shape}\")\n",
    "    print(f\"  Values: {feature_array[0]}\")\n",
    "\n",
    "    # Predict\n",
    "    probas = model.predict_proba(feature_array)\n",
    "    print(f\"\\nModel output:\")\n",
    "    print(f\"  Raw probabilities: {probas[0]}\")\n",
    "    print(\n",
    "        f\"  P(phishing) [col {meta['phish_proba_col_index']}]: {probas[0, meta['phish_proba_col_index']]:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  P(legitimate) [col {1 - meta['phish_proba_col_index']}]: {probas[0, 1 - meta['phish_proba_col_index']]:.6f}\"\n",
    "    )\n",
    "\n",
    "    if probas[0, 0] > 0.5:\n",
    "        print(f\"\\n⚠️ WARNING: Model predicts PHISHING for google.com-like features!\")\n",
    "        print(f\"   This demonstrates why whitelist is essential for OOD domains.\")\n",
    "    else:\n",
    "        print(f\"\\n✅ Model predicts LEGITIMATE for google.com-like features\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONCLUSION:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"✅ Whitelist function imported successfully\")\n",
    "print(\"✅ Major tech domains bypass model prediction\")\n",
    "print(\"✅ Fast-path optimization working as designed\")\n",
    "print(\"✅ Production model service logic validated\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae79b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test whitelist functionality with various URLs\n",
    "# test_urls = [\n",
    "#     \"https://google.com\",\n",
    "#     \"https://www.google.com\",\n",
    "#     \"https://github.com/user/repo\",\n",
    "#     \"https://suspicious-phishing-site.top/verify-account\",\n",
    "#     \"http://example.com/login?acct=12345\",\n",
    "#     \"https://paypal.com/signin\",\n",
    "#     \"https://evil-paypal-clone.tk/login\",\n",
    "# ]\n",
    "\n",
    "# print(\"=\" * 60)\n",
    "# print(\"WHITELIST TESTING\")\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# for url in test_urls:\n",
    "#     is_whitelisted = _check_whitelist(url)\n",
    "#     status = \"✅ WHITELISTED\" if is_whitelisted else \"❌ NOT WHITELISTED\"\n",
    "#     print(f\"{status:20s} | {url}\")\n",
    "\n",
    "# print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6f9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Enhanced prediction test with whitelist integration\n",
    "# def predict_with_whitelist(url: str, model, meta):\n",
    "#     \"\"\"\n",
    "#     Simulate the model service prediction logic with whitelist.\n",
    "#     Returns prediction result with source information.\n",
    "#     \"\"\"\n",
    "#     # Fast path: Check whitelist FIRST\n",
    "#     if _check_whitelist(url):\n",
    "#         return {\n",
    "#             \"url\": url,\n",
    "#             \"p_malicious\": 0.01,\n",
    "#             \"source\": \"whitelist\",\n",
    "#             \"decision\": \"ALLOW\",\n",
    "#             \"reason\": \"Known legitimate domain\",\n",
    "#         }\n",
    "\n",
    "#     # Extract features for model prediction\n",
    "#     features = extract_features(url, include_https=True)\n",
    "#     feature_array = np.array([[features[f] for f in meta[\"feature_order\"]]])\n",
    "\n",
    "#     # Model prediction\n",
    "#     probas = model.predict_proba(feature_array)\n",
    "#     p_malicious = probas[0, meta[\"phish_proba_col_index\"]]\n",
    "\n",
    "#     return {\n",
    "#         \"url\": url,\n",
    "#         \"p_malicious\": float(p_malicious),\n",
    "#         \"source\": \"model\",\n",
    "#         \"decision\": \"BLOCK\" if p_malicious > 0.5 else \"ALLOW\",\n",
    "#         \"reason\": f\"Model prediction (p={p_malicious:.4f})\",\n",
    "#     }\n",
    "\n",
    "\n",
    "# print(\"✓ Enhanced prediction function with whitelist ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "987edc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PREDICTION TEST\n",
      "============================================================\n",
      "\n",
      "Test input (google.com-like features):\n",
      "  Shape: (1, 8)\n",
      "  Values: [ 1.      0.6111  0.1765  0.2222  0.06    0.7778  4.     10.    ]\n",
      "\n",
      "Model output:\n",
      "  Raw probabilities: [1. 0.]\n",
      "  P(phishing) [col 0]: 1.000000\n",
      "  P(legitimate) [col 1]: 0.000000\n",
      "\n",
      "⚠️ WARNING: Model predicts PHISHING for google.com-like features!\n",
      "   This is expected due to OOD - whitelist will handle it.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"PREDICTION TEST\")\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "\n",
    "# # Test feature array (simulating google.com features)\n",
    "# test_features = {\n",
    "#     \"IsHTTPS\": 1.0,\n",
    "#     \"TLDLegitimateProb\": 0.6111,\n",
    "#     \"CharContinuationRate\": 0.1765,\n",
    "#     \"SpacialCharRatioInURL\": 0.2222,\n",
    "#     \"URLCharProb\": 0.06,\n",
    "#     \"LetterRatioInURL\": 0.7778,\n",
    "#     \"NoOfOtherSpecialCharsInURL\": 4.0,\n",
    "#     \"DomainLength\": 10.0,\n",
    "# }\n",
    "\n",
    "# # Create feature array in correct order\n",
    "\n",
    "# feature_array = np.array([[test_features[f] for f in meta[\"feature_order\"]]])\n",
    "\n",
    "# print(f\"\\nTest input (google.com-like features):\")\n",
    "# print(f\"  Shape: {feature_array.shape}\")\n",
    "# print(f\"  Values: {feature_array[0]}\")\n",
    "\n",
    "# # Predict\n",
    "# probas = model.predict_proba(feature_array)\n",
    "# print(f\"\\nModel output:\")\n",
    "# print(f\"  Raw probabilities: {probas[0]}\")\n",
    "# print(\n",
    "#     f\"  P(phishing) [col {meta['phish_proba_col_index']}]: {probas[0, meta['phish_proba_col_index']]:.6f}\"\n",
    "# )\n",
    "# print(\n",
    "#     f\"  P(legitimate) [col {1 - meta['phish_proba_col_index']}]: {probas[0, 1 - meta['phish_proba_col_index']]:.6f}\"\n",
    "# )\n",
    "\n",
    "# if probas[0, 0] > 0.5:\n",
    "#     print(f\"\\n⚠️ WARNING: Model predicts PHISHING for google.com-like features!\")\n",
    "#     print(f\"   This is expected due to OOD - whitelist will handle it.\")\n",
    "# else:\n",
    "#     print(f\"\\n✅ Model predicts LEGITIMATE for google.com-like features\")\n",
    "\n",
    "# print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
