{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c04bf5e",
   "metadata": {},
   "source": [
    "## **Ablation B — URL-only manifest**\n",
    "- (keep TLDLegitimateProb, exclude HTML/Title features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db06cd0",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5413dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import f1_score, average_precision_score, brier_score_loss\n",
    "from xgboost import XGBClassifier\n",
    "import mlflow\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae2b2e8",
   "metadata": {},
   "source": [
    "### **Set working directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc490286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\MLops\\NetworkSecurity\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "677b791d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 3\n",
      "python-dotenv could not parse statement starting at line 7\n",
      "python-dotenv could not parse statement starting at line 10\n",
      "python-dotenv could not parse statement starting at line 11\n",
      "python-dotenv could not parse statement starting at line 12\n",
      "python-dotenv could not parse statement starting at line 13\n",
      "python-dotenv could not parse statement starting at line 14\n",
      "python-dotenv could not parse statement starting at line 15\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "SEED = 42\n",
    "THRESH_PATH = Path(\"configs/dev/thresholds.json\")\n",
    "MLFLOW_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://localhost:5000\")\n",
    "EXPERIMENT = os.getenv(\"MLFLOW_EXPERIMENT\", \"phiusiil_baselines\")\n",
    "THRESH_PATH.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b74e23",
   "metadata": {},
   "source": [
    "### **Load dataset and yml files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3582563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fingerprint: {'rows': 235370, 'cols': 58, 'file': 'data\\\\processed\\\\phiusiil_clean_urlfeats.csv', 'md5': '30393b938e541b7b3cef650818740d20', 'added_features': ['url_len', 'url_digit_ratio', 'url_subdomains'], 'ranges': {'url_len': [14, 6097], 'url_digit_ratio': [0.0, 0.6842105263157895], 'url_subdomains': [0, 10]}}\n"
     ]
    }
   ],
   "source": [
    "DATA = Path(\"data/processed/phiusiil_clean_urlfeats.csv\")\n",
    "MANIFEST = Path(\"configs/dev/features_url_only.yaml\")\n",
    "\n",
    "# Show the fingerprint we wrote, handy for MLflow tags\n",
    "fp_path = Path(\"outputs/url_features_fingerprint.json\")\n",
    "\n",
    "if fp_path.exists():\n",
    "    print(\"Data fingerprint:\", json.loads(fp_path.read_text()))\n",
    "else:\n",
    "    print(\"Fingerprint file not found; proceed anyway.\")\n",
    "\n",
    "assert DATA.exists(), f\"Missing processed data: {DATA}\"\n",
    "assert MANIFEST.exists(), f\"Missing manifest: {MANIFEST}\"\n",
    "\n",
    "\n",
    "cfg = yaml.safe_load(MANIFEST.read_text())\n",
    "whitelist = cfg[\"include\"]\n",
    "blacklist = set(cfg.get(\"exclude\", []))\n",
    "\n",
    "df = pd.read_csv(DATA, encoding_errors=\"ignore\")\n",
    "label_col = next(\n",
    "    (c for c in df.columns if c.lower() in {\"label\", \"result\", \"y\", \"target\"}), None\n",
    ")\n",
    "assert label_col, \"No label column found in processed data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6151c0",
   "metadata": {},
   "source": [
    "### **Selects the features to include/exclude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc6955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL-only manifest (present): ['url_len', 'url_digit_ratio', 'url_subdomains', 'NoOfOtherSpecialCharsInURL', 'SpacialCharRatioInURL', 'CharContinuationRate', 'URLCharProb', 'TLDLegitimateProb']\n"
     ]
    }
   ],
   "source": [
    "# Keep exactly the whitelist columns that actually exist; drop anything else\n",
    "present = [c for c in whitelist if c in df.columns]\n",
    "missing = [c for c in whitelist if c not in df.columns]\n",
    "assert present, f\"No manifest features found. Missing from data: {missing}\"\n",
    "\n",
    "# Never allow blacklisted or non-numeric columns to slip in\n",
    "X = df[present].select_dtypes(include=[\"number\"]).copy()\n",
    "y = df[label_col].astype(int).values\n",
    "\n",
    "print(\"URL-only manifest (present):\", present)\n",
    "if missing:\n",
    "    print(\"Note: these manifest features were not found and are skipped:\", missing)\n",
    "\n",
    "# Save the resolved feature list for audit + MLflow logging later\n",
    "Path(\"outputs\").mkdir(exist_ok=True)\n",
    "Path(\"outputs/feature_manifest_resolved.json\").write_text(\n",
    "    json.dumps({\"features\": present}, indent=2)\n",
    ")\n",
    "\n",
    "# Optionally extract URLs if needed for later use\n",
    "if \"URL\" in df.columns:\n",
    "    urls = df[\"URL\"].astype(str).values\n",
    "else:\n",
    "    urls = np.array([\"\"] * len(df))\n",
    "\n",
    "# Train/val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694d8e93",
   "metadata": {},
   "source": [
    "### **Define candidates (uncalibrated base)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d2496aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_base = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),  # sparse-safe; no harm if dense\n",
    "        (\n",
    "            \"clf\",\n",
    "            LogisticRegression(\n",
    "                max_iter=2000, class_weight=\"balanced\", random_state=SEED\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "xgb_base = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=SEED,\n",
    "    n_jobs=0,\n",
    "    objective=\"binary:logistic\",\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "candidates = {\n",
    "    \"logreg\": logreg_base,\n",
    "    \"xgb\": xgb_base,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c795cf1",
   "metadata": {},
   "source": [
    "### **Fit + calibrate + score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23d8d901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MLops\\NetworkSecurity\\venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:52:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "d:\\MLops\\NetworkSecurity\\venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:52:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "d:\\MLops\\NetworkSecurity\\venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:52:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "d:\\MLops\\NetworkSecurity\\venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:52:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "d:\\MLops\\NetworkSecurity\\venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:52:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "def fit_calibrated(name, model):\n",
    "    # isotonic calibration with 5-fold CV (robust on tabular)\n",
    "\n",
    "    calib = CalibratedClassifierCV(\n",
    "        model,\n",
    "        method=\"isotonic\",\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED),\n",
    "    )\n",
    "    calib.fit(X_train, y_train)\n",
    "\n",
    "    # we need p_malicious = P(y=0). Most sklearn returns prob for class 1 -> P(y=1) (legit)\n",
    "    p_legit = calib.predict_proba(X_val)[:, 1]\n",
    "    p_mal = 1.0 - p_legit\n",
    "\n",
    "    y_hat_phish = (p_mal >= 0.5).astype(int)  # 1 means \"predict phish\"\n",
    "    y_pred = 1 - y_hat_phish  # map back to y-space (1=legit, 0=phish)\n",
    "\n",
    "    # core metrics\n",
    "    f1m = f1_score(y_val, y_pred, average=\"macro\")  # temp decision at 0.5 on p_mal\n",
    "    prauc = average_precision_score(\n",
    "        (y_val == 0).astype(int), p_mal\n",
    "    )  # AP wrt phishing as positive class\n",
    "    brier = brier_score_loss((y_val == 0).astype(int), p_mal)  # smaller=better\n",
    "    return (\n",
    "        calib,\n",
    "        {\n",
    "            \"f1_macro@0.5_on_p_mal\": float(f1m),\n",
    "            \"pr_auc_phish\": float(prauc),\n",
    "            \"brier_phish\": float(brier),\n",
    "        },\n",
    "        p_mal,\n",
    "    )\n",
    "\n",
    "\n",
    "results, calibrated, pvals = {}, {}, {}\n",
    "for name, model in candidates.items():\n",
    "    cls, metrics, p_mal = fit_calibrated(name, model)\n",
    "    calibrated[name] = cls\n",
    "    pvals[name] = p_mal\n",
    "    results[name] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263f55e",
   "metadata": {},
   "source": [
    "### **Pick best by PR-AUC (tie-break F1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "106aa1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = sorted(\n",
    "    results.items(),\n",
    "    key=lambda kv: (kv[1][\"pr_auc_phish\"], kv[1][\"f1_macro@0.5_on_p_mal\"]),\n",
    "    reverse=True,\n",
    ")\n",
    "best_name, best_metrics = order[0]\n",
    "best_model = calibrated[best_name]\n",
    "p_mal = pvals[best_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d969f08",
   "metadata": {},
   "source": [
    "### **Find single threshold (t) maximizing F1-macro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4532fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.linspace(0.05, 0.95, 19)\n",
    "f1s = []\n",
    "for t in grid:\n",
    "    y_hat = (p_mal >= t).astype(int)  # 1=phish prediction if p_mal>=t\n",
    "    # but our y is 0=phish, 1=legit → map predictions to y-space:\n",
    "    y_pred = 1 - y_hat\n",
    "    f1s.append(f1_score(y_val, y_pred, average=\"macro\"))\n",
    "t_star = float(grid[int(np.argmax(f1s))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b91956",
   "metadata": {},
   "source": [
    "### **Choose a symmetric band around t for a target gray-zone rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03f19779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t_star': 0.44999999999999996, 'low': 0.18828124999999996, 'high': 0.71171875, 'gray_zone_rate': 0.09958788290776224}\n"
     ]
    }
   ],
   "source": [
    "def pick_band_for_target(\n",
    "    p_mal: np.ndarray, t_star: float, target=0.10, tol=0.002, max_iters=40\n",
    "):\n",
    "    lo, hi = 0.0, 0.5  # search bounds on half-width\n",
    "\n",
    "    def gray(half_w):\n",
    "        low = max(0.0, t_star - half_w)\n",
    "        high = min(1.0, t_star + half_w)\n",
    "        return ((p_mal >= low) & (p_mal < high)).mean(), low, high\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        half_w = (lo + hi) / 2\n",
    "        g, low, high = gray(half_w)\n",
    "        if g > target + tol:  # too wide -> shrink\n",
    "            hi = half_w\n",
    "        elif g < target - tol:  # too narrow -> widen\n",
    "            lo = half_w\n",
    "        else:\n",
    "            low_f, high_f = float(low), float(high)\n",
    "            return low_f, high_f, float(g)\n",
    "\n",
    "    g, low, high = gray((lo + hi) / 2)\n",
    "    return float(low), float(high), float(g)\n",
    "\n",
    "\n",
    "# Compute the band\n",
    "low, high, gray = pick_band_for_target(p_mal, t_star=t_star, target=0.10)\n",
    "print({\"t_star\": float(t_star), \"low\": low, \"high\": high, \"gray_zone_rate\": gray})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccab024",
   "metadata": {},
   "source": [
    "### **Expand to gray-zone band around t targeting ~10–15%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd32ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lo, target_hi = 0.10, 0.15\n",
    "band_candidates = np.linspace(0.05, 0.40, 8)  # half-widths\n",
    "chosen = (t_star, max(0.0, t_star - 0.10), min(1.0, t_star + 0.10), 0.0)  # default\n",
    "for w in band_candidates:\n",
    "    low, high = max(0.0, t_star - w), min(1.0, t_star + w)\n",
    "    gray = ((p_mal >= low) & (p_mal < high)).mean()\n",
    "    if target_lo <= gray <= target_hi:\n",
    "        chosen = (t_star, float(low), float(high), float(gray))\n",
    "        break\n",
    "t_star, low, high, gray_rate = chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e3e58",
   "metadata": {},
   "source": [
    "### **Final metrics (forced decision and gray-zone rate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "811c0936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection: xgb {'f1_macro@0.5_on_p_mal': 0.9163419573449059, 'pr_auc_phish': 0.9577761979950676, 'brier_phish': 0.06481116607409061}\n",
      "Thresholds: {'t_star': 0.44999999999999996, 'low': 0.14999999999999997, 'high': 0.75, 'gray_zone_rate': 0.14232909886561584}\n"
     ]
    }
   ],
   "source": [
    "y_hat_star = (p_mal >= t_star).astype(int)\n",
    "y_pred_star = 1 - y_hat_star\n",
    "final_f1 = f1_score(y_val, y_pred_star, average=\"macro\")\n",
    "final_pr = average_precision_score((y_val == 0).astype(int), p_mal)\n",
    "\n",
    "summary = {\n",
    "    \"data_file\": str(DATA),\n",
    "    \"best_model\": best_name,\n",
    "    \"metrics_val\": {\n",
    "        \"pr_auc_phish\": final_pr,\n",
    "        \"f1_macro@t_star\": final_f1,\n",
    "        \"brier_phish\": brier_score_loss((y_val == 0).astype(int), p_mal),\n",
    "    },\n",
    "    \"thresholds\": {\n",
    "        \"t_star\": float(t_star),\n",
    "        \"low\": float(low),\n",
    "        \"high\": float(high),\n",
    "        \"gray_zone_rate\": float(gray),\n",
    "    },\n",
    "    \"class_mapping\": {\"phish\": 0, \"legit\": 1},\n",
    "    \"seed\": SEED,\n",
    "}\n",
    "print(\"Selection:\", best_name, best_metrics)\n",
    "print(\"Thresholds:\", summary[\"thresholds\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be95ce64",
   "metadata": {},
   "source": [
    "## **log to MLflow + export thresholds.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4f268e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/17 11:59:15 INFO mlflow.tracking.fluent: Experiment with name 'phiusiil_baselines' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run xgb_calibrated at: http://localhost:5000/#/experiments/1/runs/c80b541349ed467095e1f1155b9bf8b8\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/1\n",
      "MLflow tracking URI: http://localhost:5000\n",
      "Wrote thresholds → D:\\MLops\\NetworkSecurity\\configs\\dev\\thresholds.json\n"
     ]
    }
   ],
   "source": [
    "# log to MLflow + export thresholds.json\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "mlflow.set_experiment(EXPERIMENT)\n",
    "with mlflow.start_run(run_name=f\"{best_name}_calibrated\"):\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"model\": best_name,\n",
    "            \"calibration\": \"isotonic_cv5\",\n",
    "            \"seed\": SEED,\n",
    "            \"features\": X.shape[1],\n",
    "            \"train_rows\": int(len(X_train)),\n",
    "            \"val_rows\": int(len(X_val)),\n",
    "            \"data_file\": str(DATA),\n",
    "        }\n",
    "    )\n",
    "    mlflow.log_metrics(\n",
    "        {\n",
    "            \"val_pr_auc_phish\": summary[\"metrics_val\"][\"pr_auc_phish\"],\n",
    "            \"val_f1_macro_t_star\": summary[\"metrics_val\"][\"f1_macro@t_star\"],\n",
    "            \"val_brier_phish\": summary[\"metrics_val\"][\"brier_phish\"],\n",
    "            \"gray_zone_rate\": summary[\"thresholds\"][\"gray_zone_rate\"],\n",
    "            \"t_star\": summary[\"thresholds\"][\"t_star\"],\n",
    "            \"low\": summary[\"thresholds\"][\"low\"],\n",
    "            \"high\": summary[\"thresholds\"][\"high\"],\n",
    "        }\n",
    "    )\n",
    "    # Save/export thresholds for serving\n",
    "    with open(THRESH_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"model\": best_name,\n",
    "                \"class_mapping\": summary[\"class_mapping\"],\n",
    "                \"calibration\": {\"method\": \"isotonic\", \"cv\": 5},\n",
    "                \"thresholds\": summary[\"thresholds\"],\n",
    "                \"data\": {\"file\": summary[\"data_file\"]},\n",
    "                \"seed\": summary[\"seed\"],\n",
    "            },\n",
    "            f,\n",
    "            indent=2,\n",
    "        )\n",
    "    mlflow.log_artifact(THRESH_PATH)\n",
    "\n",
    "print(f\"MLflow tracking URI: {MLFLOW_URI}\")\n",
    "print(f\"Wrote thresholds → {THRESH_PATH.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061323d",
   "metadata": {},
   "source": [
    "## **Persist trained model + metadata for model_svc**\n",
    "\n",
    "Save the calibrated model and metadata to `models/dev/` for serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42ea9f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[artifact] model: models\\dev\\model.pkl md5: f022f9a181bd7bb406ce544f2947ad1f\n",
      "[artifact] meta : models\\dev\\model_meta.json\n",
      "[artifact] features: 8 → ['url_len', 'url_digit_ratio', 'url_subdomains', 'NoOfOtherSpecialCharsInURL', 'SpacialCharRatioInURL', 'CharContinuationRate', 'URLCharProb', 'TLDLegitimateProb'] ...\n"
     ]
    }
   ],
   "source": [
    "# === Persist trained model + metadata for model_svc ===\n",
    "from __future__ import annotations\n",
    "import json, hashlib\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# 1) Locate the fitted estimator (adjust the list if your var names differ)\n",
    "candidates = [\n",
    "    globals().get(\"calibrated_clf\"),\n",
    "    globals().get(\"calibrated_model\"),\n",
    "    globals().get(\"best_model\"),\n",
    "    globals().get(\"best_clf\"),\n",
    "    globals().get(\"final_model\"),\n",
    "    globals().get(\"clf\"),\n",
    "]\n",
    "fitted = next((m for m in candidates if m is not None), None)\n",
    "if fitted is None:\n",
    "    raise ValueError(\n",
    "        \"Could not find a fitted estimator (expected one of: calibrated_clf, calibrated_model, best_model, best_clf, final_model, clf)\"\n",
    "    )\n",
    "\n",
    "# 2) Infer feature order (priority: X_train -> X_val -> manifest include list)\n",
    "feature_order = None\n",
    "for X_name in (\"X_train\", \"X_val\", \"X_features\"):\n",
    "    if X_name in globals() and hasattr(globals()[X_name], \"columns\"):\n",
    "        feature_order = list(globals()[X_name].columns)\n",
    "        break\n",
    "if feature_order is None:\n",
    "    # fallback to config manifest\n",
    "\n",
    "    manifest_path = Path(\"configs/dev/features_url_only.yaml\")\n",
    "    if manifest_path.exists():\n",
    "        data = yaml.safe_load(manifest_path.read_text(encoding=\"utf-8\"))\n",
    "        feature_order = list(data.get(\"include\", []))\n",
    "if not feature_order:\n",
    "    raise ValueError(\n",
    "        \"Feature order not found; please expose X_train/X_val with columns or ensure configs/dev/features_url_only.yaml has 'include'.\"\n",
    "    )\n",
    "\n",
    "# 3) Determine which class id corresponds to 'phish'\n",
    "#    Our convention so far: class 0 == 'phish', class 1 == 'legit'.\n",
    "phish_class_id = 0\n",
    "if hasattr(fitted, \"classes_\"):\n",
    "    classes = list(getattr(fitted, \"classes_\"))\n",
    "    if 0 in classes:\n",
    "        phish_class_id = classes.index(0)  # index in predict_proba columns\n",
    "    else:\n",
    "        # If classes are strings or different mapping, prefer the first column but record classes\n",
    "        phish_class_id = 0\n",
    "\n",
    "# 4) Build metadata (small but sufficient for serving)\n",
    "meta = {\n",
    "    \"feature_order\": feature_order,\n",
    "    \"class_mapping\": {\"phish\": 0, \"legit\": 1},  # training-time label mapping\n",
    "    \"phish_proba_col_index\": phish_class_id,  # column index in predict_proba for P(phish)\n",
    "    \"model_type\": type(fitted).__name__,\n",
    "    \"notes\": \"URL-only baseline; calibrated; saved for model_svc.\",\n",
    "}\n",
    "\n",
    "# 5) Output paths\n",
    "ART_DIR = Path(\"models/dev\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_PATH = ART_DIR / \"model.pkl\"\n",
    "META_PATH = ART_DIR / \"model_meta.json\"\n",
    "\n",
    "# 6) Save\n",
    "joblib.dump(fitted, MODEL_PATH)\n",
    "META_PATH.write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# 7) Fingerprint for auditability\n",
    "m = hashlib.md5(MODEL_PATH.read_bytes()).hexdigest()\n",
    "print(\"[artifact] model:\", MODEL_PATH, \"md5:\", m)\n",
    "print(\"[artifact] meta :\", META_PATH)\n",
    "print(\"[artifact] features:\", len(feature_order), \"→\", feature_order[:8], \"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
