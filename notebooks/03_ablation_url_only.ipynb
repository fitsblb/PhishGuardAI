{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c04bf5e",
   "metadata": {},
   "source": [
    "## **Ablation B — URL-only manifest**\n",
    "- (keep TLDLegitimateProb, exclude HTML/Title features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db06cd0",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5413dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, json, numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import f1_score, average_precision_score, brier_score_loss\n",
    "from xgboost import XGBClassifier\n",
    "import mlflow\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae2b2e8",
   "metadata": {},
   "source": [
    "### **Set working directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc490286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\MLops\\NetworkSecurity\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677b791d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 3\n",
      "python-dotenv could not parse statement starting at line 7\n",
      "python-dotenv could not parse statement starting at line 10\n",
      "python-dotenv could not parse statement starting at line 11\n",
      "python-dotenv could not parse statement starting at line 12\n",
      "python-dotenv could not parse statement starting at line 13\n",
      "python-dotenv could not parse statement starting at line 14\n",
      "python-dotenv could not parse statement starting at line 15\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "SEED = 42\n",
    "THRESH_PATH = Path(\"configs/dev/thresholds.json\")\n",
    "MLFLOW_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://localhost:5000\")\n",
    "EXPERIMENT = os.getenv(\"MLFLOW_EXPERIMENT\", \"phiusiil_baselines\")\n",
    "THRESH_PATH.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b74e23",
   "metadata": {},
   "source": [
    "### **Load dataset and yml files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3582563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fingerprint: {'rows': 235370, 'cols': 58, 'file': 'data\\\\processed\\\\phiusiil_clean_urlfeats.csv', 'md5': '30393b938e541b7b3cef650818740d20', 'added_features': ['url_len', 'url_digit_ratio', 'url_subdomains'], 'ranges': {'url_len': [14, 6097], 'url_digit_ratio': [0.0, 0.6842105263157895], 'url_subdomains': [0, 10]}}\n"
     ]
    }
   ],
   "source": [
    "DATA = Path(\"data/processed/phiusiil_clean_urlfeats.csv\")\n",
    "MANIFEST = Path(\"configs/dev/features_url_only.yaml\")\n",
    "\n",
    "# Show the fingerprint we wrote, handy for MLflow tags\n",
    "fp_path = Path(\"outputs/url_features_fingerprint.json\")\n",
    "\n",
    "if fp_path.exists():\n",
    "    print(\"Data fingerprint:\", json.loads(fp_path.read_text()))\n",
    "else:\n",
    "    print(\"Fingerprint file not found; proceed anyway.\")\n",
    "\n",
    "assert DATA.exists(), f\"Missing processed data: {DATA}\"\n",
    "assert MANIFEST.exists(), f\"Missing manifest: {MANIFEST}\"\n",
    "\n",
    "\n",
    "cfg = yaml.safe_load(MANIFEST.read_text())\n",
    "whitelist = cfg[\"include\"]\n",
    "blacklist = set(cfg.get(\"exclude\", []))\n",
    "\n",
    "df = pd.read_csv(DATA, encoding_errors=\"ignore\")\n",
    "label_col = next((c for c in df.columns if c.lower() in {\"label\",\"result\",\"y\",\"target\"}), None)\n",
    "assert label_col, \"No label column found in processed data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6151c0",
   "metadata": {},
   "source": [
    "### **Selects the features to include/exclude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc6955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL-only manifest (present): ['url_len', 'url_digit_ratio', 'url_subdomains', 'NoOfOtherSpecialCharsInURL', 'SpacialCharRatioInURL', 'CharContinuationRate', 'URLCharProb', 'TLDLegitimateProb']\n"
     ]
    }
   ],
   "source": [
    "# Keep exactly the whitelist columns that actually exist; drop anything else\n",
    "present = [c for c in whitelist if c in df.columns]\n",
    "missing = [c for c in whitelist if c not in df.columns]\n",
    "assert present, f\"No manifest features found. Missing from data: {missing}\"\n",
    "\n",
    "# Never allow blacklisted or non-numeric columns to slip in\n",
    "X = df[present].select_dtypes(include=[\"number\"]).copy()\n",
    "y = df[label_col].astype(int).values\n",
    "\n",
    "print(\"URL-only manifest (present):\", present)\n",
    "if missing:\n",
    "    print(\"Note: these manifest features were not found and are skipped:\", missing)\n",
    "\n",
    "# Save the resolved feature list for audit + MLflow logging later\n",
    "Path(\"outputs\").mkdir(exist_ok=True)\n",
    "Path(\"outputs/feature_manifest_resolved.json\").write_text(json.dumps({\"features\": present}, indent=2))\n",
    "\n",
    "# Optionally extract URLs if needed for later use\n",
    "if \"URL\" in df.columns:\n",
    "    urls = df[\"URL\"].astype(str).values\n",
    "else:\n",
    "    urls = np.array([\"\"] * len(df))\n",
    "\n",
    "# Train/val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, stratify=y, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694d8e93",
   "metadata": {},
   "source": [
    "### **Define candidates (uncalibrated base)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d2496aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_base = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),   # sparse-safe; no harm if dense\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=SEED))\n",
    "\n",
    "])\n",
    "\n",
    "xgb_base = XGBClassifier(\n",
    "    n_estimators=300, max_depth=6, learning_rate=0.1, subsample=0.9, colsample_bytree=0.9,\n",
    "    reg_lambda=1.0, random_state=SEED, n_jobs=0, objective=\"binary:logistic\", verbose=False\n",
    ")\n",
    "\n",
    "\n",
    "candidates = {\n",
    "    \"logreg\": logreg_base,\n",
    "    \"xgb\": xgb_base,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c795cf1",
   "metadata": {},
   "source": [
    "### **Fit + calibrate + score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d8d901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MLops\\NetworkSecurity\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:36:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\MLops\\NetworkSecurity\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:36:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\MLops\\NetworkSecurity\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:36:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\MLops\\NetworkSecurity\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:36:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\MLops\\NetworkSecurity\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:36:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "def fit_calibrated(name, model):\n",
    "    # isotonic calibration with 5-fold CV (robust on tabular)\n",
    "    calib = CalibratedClassifierCV(model, \n",
    "                                   method=\"isotonic\", \n",
    "                                   cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "                                   )\n",
    "    calib.fit(X_train, y_train)\n",
    "    \n",
    "    # we need p_malicious = P(y=0). Most sklearn returns prob for class 1 -> P(y=1) (legit)\n",
    "    p_legit = calib.predict_proba(X_val)[:, 1]\n",
    "    p_mal = 1.0 - p_legit\n",
    "    \n",
    "    y_hat_phish = (p_mal >= 0.5).astype(int)   # 1 means \"predict phish\"\n",
    "    y_pred = 1 - y_hat_phish  # map back to y-space (1=legit, 0=phish)\n",
    "    \n",
    "    # core metrics                   \n",
    "    f1m = f1_score(y_val, y_pred, average=\"macro\")         # temp decision at 0.5 on p_mal\n",
    "    prauc = average_precision_score((y_val==0).astype(int), p_mal)             # AP wrt phishing as positive class\n",
    "    brier = brier_score_loss((y_val==0).astype(int), p_mal)                     # smaller=better\n",
    "    return calib, {\"f1_macro@0.5_on_p_mal\": float(f1m), \n",
    "                   \"pr_auc_phish\": float(prauc), \n",
    "                   \"brier_phish\": float(brier)}, p_mal\n",
    "\n",
    "results, calibrated, pvals = {}, {}, {}\n",
    "for name, model in candidates.items():\n",
    "    cls, metrics, p_mal = fit_calibrated(name, model)\n",
    "    calibrated[name] = cls\n",
    "    pvals[name] = p_mal\n",
    "    results[name] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263f55e",
   "metadata": {},
   "source": [
    "### **Pick best by PR-AUC (tie-break F1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "106aa1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = sorted(results.items(), key=lambda kv: (kv[1][\"pr_auc_phish\"], kv[1][\"f1_macro@0.5_on_p_mal\"]), reverse=True)\n",
    "best_name, best_metrics = order[0]\n",
    "best_model = calibrated[best_name]\n",
    "p_mal = pvals[best_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d969f08",
   "metadata": {},
   "source": [
    "### **Find single threshold (t) maximizing F1-macro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4532fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.linspace(0.05, 0.95, 19)\n",
    "f1s = []\n",
    "for t in grid:\n",
    "    y_hat = (p_mal >= t).astype(int)         # 1=phish prediction if p_mal>=t\n",
    "    # but our y is 0=phish, 1=legit → map predictions to y-space:\n",
    "    y_pred = 1 - y_hat\n",
    "    f1s.append(f1_score(y_val, y_pred, average=\"macro\"))\n",
    "t_star = float(grid[int(np.argmax(f1s))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b91956",
   "metadata": {},
   "source": [
    "### **Choose a symmetric band around t for a target gray-zone rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03f19779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t_star': 0.44999999999999996, 'low': 0.19218749999999996, 'high': 0.7078125, 'gray_zone_rate': 0.09914177677698942}\n"
     ]
    }
   ],
   "source": [
    "def pick_band_for_target(p_mal: np.ndarray, t_star: float, target=0.10, tol=0.002, max_iters=40):\n",
    "    lo, hi = 0.0, 0.5  # search bounds on half-width\n",
    "    def gray(half_w):\n",
    "        low = max(0.0, t_star - half_w)\n",
    "        high = min(1.0, t_star + half_w)\n",
    "        return ((p_mal >= low) & (p_mal < high)).mean(), low, high\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        half_w = (lo + hi) / 2\n",
    "        g, low, high = gray(half_w)\n",
    "        if g > target + tol:   # too wide -> shrink\n",
    "            hi = half_w\n",
    "        elif g < target - tol: # too narrow -> widen\n",
    "            lo = half_w\n",
    "        else:\n",
    "            low_f, high_f = float(low), float(high)\n",
    "            return low_f, high_f, float(g)\n",
    "\n",
    "    g, low, high = gray((lo + hi) / 2)\n",
    "    return float(low), float(high), float(g)\n",
    "\n",
    "# Compute the band \n",
    "low, high, gray = pick_band_for_target(p_mal, t_star=t_star, target=0.10)\n",
    "print({\"t_star\": float(t_star), \"low\": low, \"high\": high, \"gray_zone_rate\": gray})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccab024",
   "metadata": {},
   "source": [
    "### **Expand to gray-zone band around t targeting ~10–15%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd32ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lo, target_hi = 0.10, 0.15\n",
    "band_candidates = np.linspace(0.05, 0.40, 8)     # half-widths\n",
    "chosen = (t_star, max(0.0, t_star-0.10), min(1.0, t_star+0.10), 0.0)  # default\n",
    "for w in band_candidates:\n",
    "    low, high = max(0.0, t_star - w), min(1.0, t_star + w)\n",
    "    gray = ((p_mal >= low) & (p_mal < high)).mean()\n",
    "    if target_lo <= gray <= target_hi:\n",
    "        chosen = (t_star, float(low), float(high), float(gray)); break\n",
    "t_star, low, high, gray_rate = chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e3e58",
   "metadata": {},
   "source": [
    "### **Final metrics (forced decision and gray-zone rate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "811c0936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection: xgb {'f1_macro@0.5_on_p_mal': 0.9166721099659982, 'pr_auc_phish': 0.9580912093690597, 'brier_phish': 0.06462256688440587}\n",
      "Thresholds: {'t_star': 0.44999999999999996, 'low': 0.14999999999999997, 'high': 0.75, 'gray_zone_rate': 0.14424098228321366}\n"
     ]
    }
   ],
   "source": [
    "y_hat_star = (p_mal >= t_star).astype(int)\n",
    "y_pred_star = 1 - y_hat_star\n",
    "final_f1 = f1_score(y_val, y_pred_star, average=\"macro\")\n",
    "final_pr = average_precision_score((y_val==0).astype(int), p_mal)\n",
    "\n",
    "summary = {\n",
    "    \"data_file\": str(DATA),\n",
    "    \"best_model\": best_name,\n",
    "    \"metrics_val\": {\n",
    "                    \"pr_auc_phish\": final_pr,\n",
    "                    \"f1_macro@t_star\": final_f1,\n",
    "                    \"brier_phish\": brier_score_loss((y_val==0).astype(int), p_mal),\n",
    "    },\n",
    "    \"thresholds\": {\"t_star\": float(t_star),\n",
    "                    \"low\": float(low),\n",
    "                    \"high\": float(high),\n",
    "                    \"gray_zone_rate\": float(gray)},\n",
    "    \"class_mapping\": {\"phish\": 0, \n",
    "                      \"legit\": 1},\n",
    "    \"seed\": SEED,\n",
    "}\n",
    "print(\"Selection:\", best_name, best_metrics)\n",
    "print(\"Thresholds:\", summary[\"thresholds\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be95ce64",
   "metadata": {},
   "source": [
    "## **log to MLflow + export thresholds.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4f268e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run xgb_calibrated at: http://localhost:5000/#/experiments/1/runs/88a605b3a7ae4172aa40b01f9d541cc3\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/1\n",
      "MLflow tracking URI: http://localhost:5000\n",
      "Wrote thresholds → D:\\MLops\\NetworkSecurity\\configs\\dev\\thresholds.json\n"
     ]
    }
   ],
   "source": [
    "# log to MLflow + export thresholds.json\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "mlflow.set_experiment(EXPERIMENT)\n",
    "with mlflow.start_run(run_name=f\"{best_name}_calibrated\"):\n",
    "    mlflow.log_params({\n",
    "        \"model\": best_name,\n",
    "        \"calibration\": \"isotonic_cv5\",\n",
    "        \"seed\": SEED,\n",
    "        \"features\": X.shape[1],\n",
    "        \"train_rows\": int(len(X_train)),\n",
    "        \"val_rows\": int(len(X_val)),\n",
    "        \"data_file\": str(DATA),\n",
    "    })\n",
    "    mlflow.log_metrics({\n",
    "        \"val_pr_auc_phish\": summary[\"metrics_val\"][\"pr_auc_phish\"],\n",
    "        \"val_f1_macro_t_star\": summary[\"metrics_val\"][\"f1_macro@t_star\"],\n",
    "        \"val_brier_phish\": summary[\"metrics_val\"][\"brier_phish\"],\n",
    "        \"gray_zone_rate\": summary[\"thresholds\"][\"gray_zone_rate\"],\n",
    "        \"t_star\": summary[\"thresholds\"][\"t_star\"],\n",
    "        \"low\": summary[\"thresholds\"][\"low\"],\n",
    "        \"high\": summary[\"thresholds\"][\"high\"],\n",
    "    })\n",
    "    # Save/export thresholds for serving\n",
    "    with open(THRESH_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"model\": best_name,\n",
    "            \"class_mapping\": summary[\"class_mapping\"],\n",
    "            \"calibration\": {\"method\": \"isotonic\", \"cv\": 5},\n",
    "            \"thresholds\": summary[\"thresholds\"],\n",
    "            \"data\": {\"file\": summary[\"data_file\"]},\n",
    "            \"seed\": summary[\"seed\"],\n",
    "        }, f, indent=2)\n",
    "    mlflow.log_artifact(THRESH_PATH)\n",
    "\n",
    "print(f\"MLflow tracking URI: {MLFLOW_URI}\")\n",
    "print(f\"Wrote thresholds → {THRESH_PATH.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
