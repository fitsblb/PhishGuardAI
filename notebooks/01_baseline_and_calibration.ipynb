{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c942e850",
   "metadata": {},
   "source": [
    "## **Baseline-calibration** \n",
    "- this notebook is designed to build trustworthy baseline models for phishing detection. It’s not about chasing state-of-the-art performance yet — it’s about laying a solid foundation we can reason about, debug, and improve later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f859c7",
   "metadata": {},
   "source": [
    "### **Loads essential libraries for data manipulation, file handling, and visualization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d03eb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 3\n",
      "python-dotenv could not parse statement starting at line 7\n",
      "python-dotenv could not parse statement starting at line 10\n",
      "python-dotenv could not parse statement starting at line 11\n",
      "python-dotenv could not parse statement starting at line 12\n",
      "python-dotenv could not parse statement starting at line 13\n",
      "python-dotenv could not parse statement starting at line 14\n",
      "python-dotenv could not parse statement starting at line 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, json, numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import f1_score, average_precision_score, brier_score_loss\n",
    "from xgboost import XGBClassifier\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a54fcb",
   "metadata": {},
   "source": [
    "### **Set working directory to root**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4682afd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\MLops\\\\NetworkSecurity'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n",
    "os.chdir(\"../\")\n",
    "%pwd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c96a68",
   "metadata": {},
   "source": [
    "### **Config & paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c37549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "RAW = Path(\"data/raw/PhiUSIIL_Phishing_URL_Dataset.csv\")\n",
    "CLEAN = Path(\"data/processed/phiusiil_clean.csv\")\n",
    "DATA = CLEAN if CLEAN.exists() else RAW\n",
    "THRESH_PATH = Path(os.getenv(\"THRESHOLDS_JSON\", \"configs/dev/thresholds.json\"))\n",
    "MLFLOW_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://localhost:5000\")\n",
    "EXPERIMENT = os.getenv(\"MLFLOW_EXPERIMENT\", \"phiusiil_baselines\")\n",
    "THRESH_PATH.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d75d0",
   "metadata": {},
   "source": [
    "## **train, calibrate, evaluate, choose thresholds**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ed69ee",
   "metadata": {},
   "source": [
    "### **Load & split**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66643f1a",
   "metadata": {},
   "source": [
    "#### Intent: Load & Split\n",
    "\n",
    "This block loads the raw or cleaned phishing dataset, identifies the label column, and prepares the features and labels for modeling. It also handles the URL column separately, ensuring only numeric features are used for training. Finally, it splits the data into training and validation sets using stratified sampling to preserve the class balance.\n",
    "\n",
    "The goal is to set up a clean, well-structured dataset so that subsequent modeling steps are reliable and reproducible. This step is crucial for ensuring that the model is trained and evaluated on representative data, minimizing bias and data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a5b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA, encoding_errors = \"ignore\")\n",
    "label_col = next((c for c in df.columns if c.lower() in {\"label\",\"result\",\"y\",\"target\"}), None)\n",
    "assert label_col is not None, \"No label column found\"\n",
    "\n",
    "y = df[label_col].astype(int).values            # 1=legit, 0=phish\n",
    "X = df.drop(columns=[label_col], axis=1)\n",
    "\n",
    "\n",
    "if \"URL\" in X.columns:                         # Keep url from the X columns\n",
    "    urls = X[\"URL\"].astype(str).values\n",
    "    X = X.drop(columns=[\"URL\"])\n",
    "\n",
    "else:\n",
    "    urls = np.array([\"\"] * len(X))            # Create placeholder URLs\n",
    "\n",
    "\n",
    "# Keep only numeric values\n",
    "X = X.select_dtypes(include=[\"number\"]).copy()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, stratify=y, random_state=SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e61befe",
   "metadata": {},
   "source": [
    "### **Define candidates (uncalibrated base)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_base = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),   # sparse-safe; no harm if dense\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=SEED))\n",
    "\n",
    "])\n",
    "\n",
    "xgb_base = XGBClassifier(\n",
    "    n_estimators=300, max_depth=6, learning_rate=0.1, subsample=0.9, colsample_bytree=0.9,\n",
    "    reg_lambda=1.0, random_state=SEED, n_jobs=0, objective=\"binary:logistic\", verbose=False\n",
    ")\n",
    "\n",
    "\n",
    "candidates = {\n",
    "    \"logreg\": logreg_base,\n",
    "    \"xgb\": xgb_base,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6570c4ce",
   "metadata": {},
   "source": [
    "### **Fit + calibrate + score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9e0837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_calibrated(name, model):\n",
    "    # isotonic calibration with 5-fold CV (robust on tabular)\n",
    "    calib = CalibratedClassifierCV(model, \n",
    "                                   method=\"isotonic\", \n",
    "                                   cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "                                   )\n",
    "    calib.fit(X_train, y_train)\n",
    "    \n",
    "    # we need p_malicious = P(y=0). Most sklearn returns prob for class 1 -> P(y=1) (legit)\n",
    "    p_legit = calib.predict_proba(X_val)[:, 1]\n",
    "    p_mal = 1.0 - p_legit\n",
    "    \n",
    "    # core metrics\n",
    "    f1m = f1_score(y_val, (p_mal >= 0.5).astype(int), average=\"macro\")         # temp decision at 0.5 on p_mal\n",
    "    prauc = average_precision_score((y_val==0).astype(int), p_mal)             # AP wrt phishing as positive class\n",
    "    brier = brier_score_loss((y_val==0).astype(int), p_mal)                     # smaller=better\n",
    "    return calib, {\"f1_macro@0.5_on_p_mal\": float(f1m), \n",
    "                   \"pr_auc_phish\": float(prauc), \n",
    "                   \"brier_phish\": float(brier)}, p_mal\n",
    "\n",
    "results, calibrated, pvals = {}, {}, {}\n",
    "for name, model in candidates.items():\n",
    "    cls, metrics, p_mal = fit_calibrated(name, model)\n",
    "    calibrated[name] = cls\n",
    "    pvals[name] = p_mal\n",
    "    results[name] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e36fd2",
   "metadata": {},
   "source": [
    "### **Pick best by PR-AUC (tie-break F1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cb82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = sorted(results.items(), key=lambda kv: (kv[1][\"pr_auc_phish\"], kv[1][\"f1_macro@0.5_on_p_mal\"]), reverse=True)\n",
    "best_name, best_metrics = order[0]\n",
    "best_model = calibrated[best_name]\n",
    "p_mal = pvals[best_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af2e04",
   "metadata": {},
   "source": [
    "### **Find single threshold (t) maximizing F1-macro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49956973",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.linspace(0.05, 0.95, 19)\n",
    "f1s = []\n",
    "for t in grid:\n",
    "    y_hat = (p_mal >= t).astype(int)         # 1=phish prediction if p_mal>=t\n",
    "    # but our y is 0=phish, 1=legit → map predictions to y-space:\n",
    "    y_pred = 1 - y_hat\n",
    "    f1s.append(f1_score(y_val, y_pred, average=\"macro\"))\n",
    "t_star = float(grid[int(np.argmax(f1s))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe117ae5",
   "metadata": {},
   "source": [
    "### **Expand to gray-zone band around t targeting ~10–15%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lo, target_hi = 0.10, 0.15\n",
    "band_candidates = np.linspace(0.05, 0.40, 8)     # half-widths\n",
    "chosen = (t_star, max(0.0, t_star-0.10), min(1.0, t_star+0.10), 0.0)  # default\n",
    "for w in band_candidates:\n",
    "    low, high = max(0.0, t_star - w), min(1.0, t_star + w)\n",
    "    gray = ((p_mal >= low) & (p_mal < high)).mean()\n",
    "    if target_lo <= gray <= target_hi:\n",
    "        chosen = (t_star, float(low), float(high), float(gray)); break\n",
    "t_star, low, high, gray_rate = chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f9cc6",
   "metadata": {},
   "source": [
    "### **Final metrics (forced decision and gray-zone rate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_star = (p_mal >= t_star).astype(int)\n",
    "y_pred_star = 1 - y_hat_star\n",
    "final_f1 = f1_score(y_val, y_pred_star, average=\"macro\")\n",
    "final_pr = average_precision_score((y_val==0).astype(int), p_mal)\n",
    "\n",
    "summary = {\n",
    "    \"data_file\": str(DATA),\n",
    "    \"best_model\": best_name,\n",
    "    \"metrics_val\": {\n",
    "        \"pr_auc_phish\": final_pr,\n",
    "        \"f1_macro@t_star\": final_f1,\n",
    "        \"brier_phish\": brier_score_loss((y_val==0).astype(int), p_mal),\n",
    "    },\n",
    "    \"thresholds\": {\"t_star\": t_star, \"low\": low, \"high\": high, \"gray_zone_rate\": gray_rate},\n",
    "    \"class_mapping\": {\"phish\": 0, \"legit\": 1},\n",
    "    \"seed\": SEED,\n",
    "}\n",
    "print(\"Selection:\", best_name, best_metrics)\n",
    "print(\"Thresholds:\", summary[\"thresholds\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
