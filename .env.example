# Judge backend: stub | llm
JUDGE_BACKEND=stub

# LLM Judge (used when JUDGE_BACKEND=llm)
OLLAMA_HOST=http://localhost:11434
JUDGE_MODEL=llama3.2:1b
JUDGE_TIMEOUT_SECS=12
# Optional: store models off C: to save space
# OLLAMA_MODELS=D:\ollama\models

# MongoDB Audit Logging (Optional)
MONGO_URI=
MONGO_DB=phishguard

# Thresholds (use the tuned URL-only thresholds by default)
THRESHOLDS_JSON=configs/dev/thresholds.json

# ============================================================
# MODEL SERVICE CONFIGURATION
# ============================================================

# Configuration file path (can be overridden for different environments)
CONFIG_PATH=configs/dev/config.yaml

# Primary model (production model used for decisions)
MODEL_PATH=models/dev/model_7feat.pkl
MODEL_META_PATH=models/dev/model_7feat_meta.json

# Shadow testing (A/B testing with 8-feature model)
SHADOW_ENABLED=true
SHADOW_MODEL_PATH=models/dev/model_8feat.pkl
SHADOW_META_PATH=models/dev/model_8feat_meta.json

# Model service URL (used by gateway to call model service)
MODEL_SVC_URL=http://localhost:9000